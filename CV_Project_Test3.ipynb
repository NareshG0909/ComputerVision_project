{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4epZUuS_x4BE",
        "outputId": "c0e85b5d-b225-48af-c1d1-1aaeaff2395c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model Accuracy: 0.6640316205533597\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.76      0.78      0.77        81\n",
            "       glass       0.59      0.65      0.62       100\n",
            "       metal       0.63      0.61      0.62        82\n",
            "       paper       0.75      0.74      0.75       119\n",
            "     plastic       0.56      0.60      0.58        97\n",
            "       trash       0.92      0.44      0.60        27\n",
            "\n",
            "    accuracy                           0.66       506\n",
            "   macro avg       0.70      0.64      0.66       506\n",
            "weighted avg       0.67      0.66      0.66       506\n",
            "\n",
            "Model and scaler saved successfully in /content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests2!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset Path\n",
        "dataset_path = '/content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests/Dataset_test'\n",
        "\n",
        "# Define label mapping for multiple classes\n",
        "label_map = {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n",
        "num_classes = len(label_map)  # Ensure correct number of classes\n",
        "\n",
        "# Function to extract features (HOG + Color Histogram)\n",
        "def extract_features(img):\n",
        "    # Resize Image\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "\n",
        "    # Convert to Grayscale\n",
        "    gray = rgb2gray(img)\n",
        "\n",
        "    # HOG Feature Extraction\n",
        "    hog_features, _ = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
        "                          cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "\n",
        "    # Color Histogram (RGB)\n",
        "    hist_r = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()\n",
        "    hist_g = cv2.calcHist([img], [1], None, [256], [0, 256]).flatten()\n",
        "    hist_b = cv2.calcHist([img], [2], None, [256], [0, 256]).flatten()\n",
        "\n",
        "    # Normalize histograms (avoid division by zero)\n",
        "    hist_r = hist_r / hist_r.sum() if hist_r.sum() != 0 else hist_r\n",
        "    hist_g = hist_g / hist_g.sum() if hist_g.sum() != 0 else hist_g\n",
        "    hist_b = hist_b / hist_b.sum() if hist_b.sum() != 0 else hist_b\n",
        "\n",
        "    # Concatenate features\n",
        "    features = np.hstack([hog_features, hist_r, hist_g, hist_b])\n",
        "    return features\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for folder in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        if os.path.isdir(folder_path) and folder in label_map:\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "\n",
        "                # Read image\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue  # Skip corrupted images\n",
        "\n",
        "                # Extract features\n",
        "                features = extract_features(img)\n",
        "\n",
        "                images.append(features)\n",
        "                labels.append(label_map[folder])  # Multi-class labels\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load Dataset\n",
        "images, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Normalize Features\n",
        "scaler = StandardScaler()\n",
        "images = scaler.fit_transform(images)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Train Classifier (SVM or Random Forest)\n",
        "classifier = SVC(kernel='linear', C=1.0)  # Change to RandomForestClassifier(n_estimators=100) if needed\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred, target_names=list(label_map.keys())))\n",
        "\n",
        "# Define save directory and ensure it exists\n",
        "save_dir = \"/content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests2\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save Model and Scaler\n",
        "joblib.dump(classifier, os.path.join(save_dir, \"traditional_model.pkl\"))\n",
        "joblib.dump(scaler, os.path.join(save_dir, \"scaler.pkl\"))\n",
        "\n",
        "print(f\"Model and scaler saved successfully in {save_dir}!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "# Load the trained model and scaler\n",
        "model = joblib.load(\"/content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests2/traditional_model.pkl\")\n",
        "scaler = joblib.load(\"/content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests2/scaler.pkl\")\n",
        "\n",
        "# Define label mapping (same as training)\n",
        "label_map = {0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n",
        "\n",
        "# Function to extract features from a single image (HOG + Color Histogram)\n",
        "def extract_features(img):\n",
        "    img = cv2.resize(img, (128, 128))  # Resize image\n",
        "\n",
        "    gray = rgb2gray(img)  # Convert to grayscale\n",
        "\n",
        "    # Extract HOG features\n",
        "    hog_features, _ = hog(gray, orientations=9, pixels_per_cell=(8, 8),\n",
        "                          cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "\n",
        "    # Extract Color Histogram\n",
        "    hist_r = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()\n",
        "    hist_g = cv2.calcHist([img], [1], None, [256], [0, 256]).flatten()\n",
        "    hist_b = cv2.calcHist([img], [2], None, [256], [0, 256]).flatten()\n",
        "\n",
        "    # Normalize histograms\n",
        "    hist_r = hist_r / hist_r.sum() if hist_r.sum() != 0 else hist_r\n",
        "    hist_g = hist_g / hist_g.sum() if hist_g.sum() != 0 else hist_g\n",
        "    hist_b = hist_b / hist_b.sum() if hist_b.sum() != 0 else hist_b\n",
        "\n",
        "    # Concatenate features\n",
        "    features = np.hstack([hog_features, hist_r, hist_g, hist_b])\n",
        "    return features\n",
        "\n",
        "# Function to predict image class\n",
        "def predict_image(image_path):\n",
        "    img = cv2.imread(image_path)  # Read input image\n",
        "    if img is None:\n",
        "        print(\"Error: Unable to read image!\")\n",
        "        return\n",
        "\n",
        "    features = extract_features(img)  # Extract features\n",
        "    features = scaler.transform([features])  # Normalize features using the saved scaler\n",
        "\n",
        "    prediction = model.predict(features)  # Predict class\n",
        "    print(f\"Predicted Class: {label_map[prediction[0]]}\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/M.Tech/Computer Vision/Project/Tests/Dataset_test/cardboard/cardboard104.jpg\"\n",
        "predict_image(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVAYzKjCzYX2",
        "outputId": "2c657041-0062-4de5-bc42-8634408cf6db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: cardboard\n"
          ]
        }
      ]
    }
  ]
}